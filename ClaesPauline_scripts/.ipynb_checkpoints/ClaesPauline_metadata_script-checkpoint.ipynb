{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7096bc89-2bf0-4209-98df-008eba77cbac",
   "metadata": {},
   "source": [
    "Claes Pauline. Master Digital Text Analysis. Student ID: 20163274\n",
    "\n",
    "# Metadata\n",
    "This script contains all code used for adding metadata to data frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1cd408-4a6a-48a4-a5ad-add92b8ef4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd558da4-4df9-4698-9c60-54b64f41c981",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Add wordcounts to French data\n",
    "While English textdata already have information on word counts from EEBO and EMMA metadata, I do not have this for the French data. Therefore, this needs to be counted. For French texts coming from Frantext as well as Google Books, all textdata was parsed into a data frame of four columns (Word, Lemma, POS, filename), containing one row per word. Therefore, it makes sense to group that data frame per filename and count the number of rows that each file contains (as one word = one row). However, it needs to be filtered, since punctuation needs to be excluded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "strategic-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "modular-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "wlp_frantext_early = read(\"/Users/paulineclaes/Documents/dta/Thesis/Data/Dataframes/WLP/frantext_WLP_early.csv\")\n",
    "wlp_epub_early = read(\"/Users/paulineclaes/Documents/dta/Thesis/Data/Dataframes/WLP/epub_WLP_early.csv\")\n",
    "wlp_frantext_later = read(\"/Users/paulineclaes/Documents/dta/Thesis/Data/Dataframes/WLP/frantext_WLP_later.csv\")\n",
    "wlp_epub_later = read(\"/Users/paulineclaes/Documents/dta/Thesis/Data/Dataframes/WLP/epub_WLP_later.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "processed-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_separate_df_per_filename(df):\n",
    "    \"\"\"Function to get a separate data frame per file name. \n",
    "    Takes as input the WLP data frame, prints the number of words excluding punctuation and spaces.\"\"\"\n",
    "    \n",
    "    for filename in df[\"file_name\"].unique(): # for each unique filename in data frame\n",
    "        new_df = df[df[\"file_name\"] == filename] # construct a new df of only that file name\n",
    "        new_df = new_df.drop(new_df.index[new_df['POS'].isin([\"PUNCT\", \"PONCT\", \"SPACE\"])], axis=0) # drop punctuation and spaces using their POS-tags\n",
    "        print(f\"filename: {filename} \\tTokens: {len(new_df)}\\n\") # print the filename and the number of rows in that data frame ( so the number of words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "academic-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_per_filename(df):\n",
    "    \"\"\"Function to get a separate data frame per file name. \n",
    "    Takes as input the WLP data frame, adds the file name and its number of words excluding punctuation and spaces to a dictionary.\n",
    "    Key = filename, value = number of words.\n",
    "    \"\"\"\n",
    "    \n",
    "    author_dict = {}\n",
    "    for filename in df[\"file_name\"].unique():\n",
    "        new_df = df[df[\"file_name\"] == filename]\n",
    "        new_df = new_df.drop(new_df.index[new_df['POS'].isin([\"PUNCT\", \"PONCT\", \"SPACE\"])], axis=0) # drop punctuation and spaces using their POS-tags\n",
    "        author_dict[filename] = len(new_df)\n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "noticed-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dict1, dict2):\n",
    "    dict1.update(dict2)\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f6328-ab4f-4e14-9d21-00592e54b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE \n",
    "# building the dictionary to contain the wordcounts\n",
    "\n",
    "author_dict_frantext = get_dict_per_filename(wlp_frantext_early) # wordcounts for frantext WLP\n",
    "author_dict_epub = get_dict_per_filename(wlp_epub_early) # wordcounts for EPUB WLP\n",
    "author_dict = merge_dicts(author_dict_frantext, author_dict_epub) # add them to one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "tribal-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE\n",
    "# read in the data frame that we want to map the word counts to (per file name)\n",
    "df = pd.read_csv(\"/Users/paulineclaes/Documents/dta/Thesis/Data/Dataframes/concordance/all_early_concordance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "stable-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a column containing the wordcounts based on the file name column\n",
    "df.insert(5, \"all_tokens\", df[\"filename\"].map(author_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9e861c-1b8d-4f8d-9223-002a69b6f664",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge metadata with concordance dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf24c24-e1a3-4e68-82dd-d7d1ab61967b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Assigning a unique ID to each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad12857f-d358-4a71-b94f-e4ee41fb4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/paulineclaes/Documents/dta/thesis/ClaesPauline_thesis_finaleversie/data/final_metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a3fec493-e469-4427-a856-88decf83dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign unique number to authors, starting from 1 \n",
    "df.insert(3, \"author_id\", df.groupby([\"author\"], sort=False).ngroup()+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3787302a-7fec-4ff5-b4a7-f390031f4b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_id_list = [] # instantiate empty list\n",
    "for author_id, author_df in df.groupby([\"author_id\"]): # groupby author and iterate\n",
    "    author_df = author_df.reset_index() # reset the index to the author\n",
    "    author_df.insert(5, \"text_id_per_author\", author_df.index+1) # number of texts per author (count restarts at 1 for each new author)\n",
    "    author_id_list.append(author_df) # add to list\n",
    "    \n",
    "new_df = pd.concat(author_id_list).reset_index(drop=True) # get it into one dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0064c856-b197-449e-afc8-f8a959042dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge authorIDs with textIDs, so that each text effectively has a unique ID \n",
    "new_df.insert(6, \n",
    "              \"authorId_textId\", \n",
    "              [f\"{row['author_id']}_{row['text_id_per_author']}\" for index, row in new_df.iloc[:, 4:6].iterrows()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c700c779-b350-4cbe-a714-a4f84fcee1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a new column that indicates whether a text is a translation, reference text or source text\n",
    "new_df.insert(7, \"transl_ref_srcTxt\", \n",
    "              [\"transl\" if \"T\" in value else \"srcTxt\" if \"FS\" in value else \"ref\" for value in new_df[\"data_identifier\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d2e02a-ffd4-4baf-a42a-2a74cb255fd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Mapping metadata to concordance dataframe \n",
    "(inserting unique identifiers per text, and other information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8a467ccb-5849-4410-8fee-89af8f0085d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to map metadata dictionary with key=filename to the dataframe\n",
    "\n",
    "def map_filename_dict_to_df(source_df, target_df, target_index, target_colname, col1, col2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments: source_df, target_df, target_index, target_colname, col1, col2\n",
    "    - source_df: metadata df\n",
    "    - target_df : df you want to insert metadata \n",
    "    - target_index: index you want new column to be\n",
    "    - target_colname: column name you want new column to have\n",
    "    - col1: column name of column you want the metadata to be based on (so a column that is shared across dataframes)\n",
    "    - col2: the column containing information you want to transfer across dataframes.\n",
    "    \n",
    "    Actual function: \n",
    "    def map_filename_dict_to_df(source_df, target_df, target_index, target_colname, col1, col2):\n",
    "        filename_dict = {filename:value for filename, value in zip(source_df[col1], source_df[col2])}\n",
    "        target_df.insert(target_index, target_colname, target_df[col1].map(filename_dict))\n",
    "    \n",
    "        return target_df\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    filename_dict = {filename:value for filename, value in zip(source_df[col1], source_df[col2])}\n",
    "    target_df.insert(target_index, target_colname, target_df[col1].map(filename_dict))\n",
    "    \n",
    "    return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e147b2-dc51-4e37-9170-09dc7f8f915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE of doing it for 1 column\n",
    "\n",
    "\n",
    "# add unique author id based on the unique data identifier\n",
    "f = map_filename_dict_to_df(source_df = m, \n",
    "                            target_df = f,\n",
    "                            target_index=3,\n",
    "                            target_colname=\"author_id\",\n",
    "                            col1 = \"data_identifier\", \n",
    "                            col2 = \"author_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c48829c8-23bd-4d44-a11a-df7a06b0705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 10\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE of doing it in bulk at once\n",
    "\n",
    "\n",
    "col_list = [\"period\", \n",
    "            \"data_identifier\", \n",
    "            \"author_id\", \n",
    "            \"text_id_per_author\", \n",
    "            \"authorId_textId\", \n",
    "            \"title\", \n",
    "            \"USTC_subject_classification\", \n",
    "            \"author\", \n",
    "            \"textDate\", \"wordcount\"]\n",
    "print(len(col_list))\n",
    "index_list = [i for i in range(0, len(col_list))]\n",
    "print(index_list, len(index_list))\n",
    "\n",
    "for col_name, col_ix in zip(col_list, index_list):\n",
    "    addData = map_filename_dict_to_df(\n",
    "        source_df = m, \n",
    "        target_df = addData, \n",
    "        target_index = col_ix, \n",
    "        target_colname = col_name, \n",
    "        col1 = \"filename\", \n",
    "        col2 = col_name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8fd3c5-9209-4d5f-9d10-ce1e1f0d32fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Add numeric period category\n",
    "\n",
    "For the English data, we have a classification into decades: 1580-1589, 1590-1599, ...\n",
    "\n",
    "We now want to turn this into a numeric variable. There are 5 decades in total (1580-1589, 1590-1599, 1600-1609, 1680-1689, 1690-1699). These will be assigned a number chronologically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058719ee-f3d3-4d9d-9827-2408214a13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = pd.read_excel('/Users/paulineclaes/Documents/dta/thesis/finaldata/final_GoToInf.xlsx')\n",
    "fr = pd.read_excel('/Users/paulineclaes/Documents/dta/thesis/finaldata/final_AllerINF.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebdd15b-469a-4382-8111-a2adfa369986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>data_identifier</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text_id_per_author</th>\n",
       "      <th>authorId_textId</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>textDate</th>\n",
       "      <th>...</th>\n",
       "      <th>position</th>\n",
       "      <th>position_fronting</th>\n",
       "      <th>argmt</th>\n",
       "      <th>adverbial</th>\n",
       "      <th>split</th>\n",
       "      <th>attention?</th>\n",
       "      <th>preceding_context</th>\n",
       "      <th>match</th>\n",
       "      <th>following_context</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600-1609</td>\n",
       "      <td>ET13</td>\n",
       "      <td>early</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11_1</td>\n",
       "      <td>A05339.xml</td>\n",
       "      <td>Noua Francia : or The description of that part...</td>\n",
       "      <td>Erondelle, P.</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, neere about the  Açors,  well fil led with ...</td>\n",
       "      <td>going</td>\n",
       "      <td>a fiſhing for New-found-land-fiſh. And they as...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600-1609</td>\n",
       "      <td>ET09</td>\n",
       "      <td>early</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8_1</td>\n",
       "      <td>A01991.xml</td>\n",
       "      <td>Admirable and memorable histories containing t...</td>\n",
       "      <td>Grimeston, Edward</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, by reason of the greatnesse and length. Thi...</td>\n",
       "      <td>going</td>\n",
       "      <td>a iourney with his Wa gon, was be-nighted and ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600-1609</td>\n",
       "      <td>ET13</td>\n",
       "      <td>early</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11_1</td>\n",
       "      <td>A05339.xml</td>\n",
       "      <td>Noua Francia : or The description of that part...</td>\n",
       "      <td>Erondelle, P.</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hogſ heads of Meale, which were giuen to the...</td>\n",
       "      <td>going</td>\n",
       "      <td>a way.  The eleuenth of Auguſt the ſaid  Monſi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600-1609</td>\n",
       "      <td>ET14</td>\n",
       "      <td>early</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12_1</td>\n",
       "      <td>99850354.xml</td>\n",
       "      <td>Fovvre bookes, of the institution, vse and doc...</td>\n",
       "      <td>anon10</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:               that is,               of a s...</td>\n",
       "      <td>going</td>\n",
       "      <td>about it seauen               times,          ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600-1609</td>\n",
       "      <td>ET14</td>\n",
       "      <td>early</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12_1</td>\n",
       "      <td>99850354.xml</td>\n",
       "      <td>Fovvre bookes, of the institution, vse and doc...</td>\n",
       "      <td>anon10</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>impotencie                weaknesse          ...</td>\n",
       "      <td>going</td>\n",
       "      <td>about to adore the Head in heauen,            ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      period data_identifier timeframe  author_id  text_id_per_author  \\\n",
       "0  1600-1609            ET13     early         11                   1   \n",
       "1  1600-1609            ET09     early          8                   1   \n",
       "2  1600-1609            ET13     early         11                   1   \n",
       "3  1600-1609            ET14     early         12                   1   \n",
       "4  1600-1609            ET14     early         12                   1   \n",
       "\n",
       "  authorId_textId      filename  \\\n",
       "0            11_1    A05339.xml   \n",
       "1             8_1    A01991.xml   \n",
       "2            11_1    A05339.xml   \n",
       "3            12_1  99850354.xml   \n",
       "4            12_1  99850354.xml   \n",
       "\n",
       "                                               title             author  \\\n",
       "0  Noua Francia : or The description of that part...      Erondelle, P.   \n",
       "1  Admirable and memorable histories containing t...  Grimeston, Edward   \n",
       "2  Noua Francia : or The description of that part...      Erondelle, P.   \n",
       "3  Fovvre bookes, of the institution, vse and doc...             anon10   \n",
       "4  Fovvre bookes, of the institution, vse and doc...             anon10   \n",
       "\n",
       "   textDate  ...  position position_fronting argmt adverbial split attention?  \\\n",
       "0    1609.0  ...       NaN               NaN   NaN       NaN   NaN        NaN   \n",
       "1    1607.0  ...       NaN               NaN   NaN       NaN   NaN        NaN   \n",
       "2    1609.0  ...       NaN               NaN   NaN       NaN   NaN        NaN   \n",
       "3    1600.0  ...       NaN               NaN   NaN       NaN   NaN        NaN   \n",
       "4    1600.0  ...       NaN               NaN   NaN       NaN   NaN        NaN   \n",
       "\n",
       "                                   preceding_context                 match  \\\n",
       "0   , neere about the  Açors,  well fil led with ...                going    \n",
       "1   , by reason of the greatnesse and length. Thi...                going    \n",
       "2    hogſ heads of Meale, which were giuen to the...                going    \n",
       "3   :               that is,               of a s...  going                  \n",
       "4   impotencie                weaknesse          ...  going                  \n",
       "\n",
       "                                   following_context note  \n",
       "0  a fiſhing for New-found-land-fiſh. And they as...  NaN  \n",
       "1  a iourney with his Wa gon, was be-nighted and ...  NaN  \n",
       "2  a way.  The eleuenth of Auguſt the ſaid  Monſi...  NaN  \n",
       "3  about it seauen               times,          ...  NaN  \n",
       "4  about to adore the Head in heauen,            ...  NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101de579-2592-42c6-8e08-9819d561bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "en.insert(1, \"period_category\", en.groupby([\"period\"], sort=True).ngroup()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3f3e5-856d-4b57-aee6-fdd1e87b7489",
   "metadata": {},
   "source": [
    "> However, for French data, this is less straightforward, since these were not first classified into decades, and have a wider range of text dates, since they precede the corresponding English translation.\n",
    "\n",
    "> Therefore, the range of possible textdates for French is divided into 5 equal chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83950b84-7baf-460a-80ea-d0858b9f1614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeframe</th>\n",
       "      <th>kind</th>\n",
       "      <th>data_identifier</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text_id_per_author</th>\n",
       "      <th>authorId_textId</th>\n",
       "      <th>fr_source_filename</th>\n",
       "      <th>fr_source_title</th>\n",
       "      <th>fr_source_author</th>\n",
       "      <th>fr_source_textDate</th>\n",
       "      <th>...</th>\n",
       "      <th>vpers</th>\n",
       "      <th>pos</th>\n",
       "      <th>previous50</th>\n",
       "      <th>prev1</th>\n",
       "      <th>aller</th>\n",
       "      <th>aller_POS</th>\n",
       "      <th>INF</th>\n",
       "      <th>next1</th>\n",
       "      <th>next1_POS</th>\n",
       "      <th>next50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>early</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS01</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35_1</td>\n",
       "      <td>WFtemp_LABE_Debat_de_folie_et_amour</td>\n",
       "      <td>Débat de folie et d'amour</td>\n",
       "      <td>Labé, Louise</td>\n",
       "      <td>1555</td>\n",
       "      <td>...</td>\n",
       "      <td>3sg</td>\n",
       "      <td>inf</td>\n",
       "      <td>à gouverner les Viles , sans que lon l' apelle...</td>\n",
       "      <td>d'</td>\n",
       "      <td>aller</td>\n",
       "      <td>VINF</td>\n",
       "      <td>planter</td>\n",
       "      <td>des</td>\n",
       "      <td>P+D</td>\n",
       "      <td>chous . Le fol ira tant et viendra , en donner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>early</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS01</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35_1</td>\n",
       "      <td>WFtemp_LABE_Debat_de_folie_et_amour</td>\n",
       "      <td>Débat de folie et d'amour</td>\n",
       "      <td>Labé, Louise</td>\n",
       "      <td>1555</td>\n",
       "      <td>...</td>\n",
       "      <td>3sg</td>\n",
       "      <td>pres</td>\n",
       "      <td>ay dit . Quand Mercure ut fini la defense de F...</td>\n",
       "      <td>,</td>\n",
       "      <td>và</td>\n",
       "      <td>VP</td>\n",
       "      <td>prononcer</td>\n",
       "      <td>un</td>\n",
       "      <td>DET</td>\n",
       "      <td>arrest interlocutoire en cette maniere : Pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>early</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS13</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>47_1</td>\n",
       "      <td>LESCARBOT_cleaned</td>\n",
       "      <td>Histoire de la Nouvelle France (Lescarbot, Marc)</td>\n",
       "      <td>Lescarbot, Marc</td>\n",
       "      <td>1609</td>\n",
       "      <td>...</td>\n",
       "      <td>3sg</td>\n",
       "      <td>past</td>\n",
       "      <td>de Canada &amp; Hochelaga au temps de post Tacques...</td>\n",
       "      <td>est</td>\n",
       "      <td>allé</td>\n",
       "      <td>VPP</td>\n",
       "      <td>rechercher</td>\n",
       "      <td>leurs</td>\n",
       "      <td>DET</td>\n",
       "      <td>pelleteries , Canada que pour icelles ils ont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>early</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS13</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>47_1</td>\n",
       "      <td>LESCARBOT_cleaned</td>\n",
       "      <td>Histoire de la Nouvelle France (Lescarbot, Marc)</td>\n",
       "      <td>Lescarbot, Marc</td>\n",
       "      <td>1609</td>\n",
       "      <td>...</td>\n",
       "      <td>3pl</td>\n",
       "      <td>pres</td>\n",
       "      <td>qu' vn autre &amp; n' en perdent point yn tour de ...</td>\n",
       "      <td>les</td>\n",
       "      <td>vont</td>\n",
       "      <td>VP</td>\n",
       "      <td>voir</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>plus grand chose : comme pardeça quand on pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS13</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>47_1</td>\n",
       "      <td>LESCARBOT_cleaned</td>\n",
       "      <td>Histoire de la Nouvelle France (Lescarbot, Marc)</td>\n",
       "      <td>Lescarbot, Marc</td>\n",
       "      <td>1609</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>pres</td>\n",
       "      <td>à l' vn des bours dudit lac ne nous apparoisso...</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>aller</td>\n",
       "      <td>VINF</td>\n",
       "      <td>chercher</td>\n",
       "      <td>passage</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>tre ou cinq rivieres toutes sortantes dudit ff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timeframe             kind data_identifier  author_id  text_id_per_author  \\\n",
       "0     early  french_original           EFS01         35                   1   \n",
       "1     early  french_original           EFS01         35                   1   \n",
       "2     early  french_original           EFS13         47                   1   \n",
       "3     early  french_original           EFS13         47                   1   \n",
       "4     early  french_original           EFS13         47                   1   \n",
       "\n",
       "  authorId_textId                   fr_source_filename  \\\n",
       "0            35_1  WFtemp_LABE_Debat_de_folie_et_amour   \n",
       "1            35_1  WFtemp_LABE_Debat_de_folie_et_amour   \n",
       "2            47_1                    LESCARBOT_cleaned   \n",
       "3            47_1                    LESCARBOT_cleaned   \n",
       "4            47_1                    LESCARBOT_cleaned   \n",
       "\n",
       "                                    fr_source_title fr_source_author  \\\n",
       "0                         Débat de folie et d'amour     Labé, Louise   \n",
       "1                         Débat de folie et d'amour     Labé, Louise   \n",
       "2  Histoire de la Nouvelle France (Lescarbot, Marc)  Lescarbot, Marc   \n",
       "3  Histoire de la Nouvelle France (Lescarbot, Marc)  Lescarbot, Marc   \n",
       "4  Histoire de la Nouvelle France (Lescarbot, Marc)  Lescarbot, Marc   \n",
       "\n",
       "   fr_source_textDate  ... vpers   pos  \\\n",
       "0                1555  ...   3sg   inf   \n",
       "1                1555  ...   3sg  pres   \n",
       "2                1609  ...   3sg  past   \n",
       "3                1609  ...   3pl  pres   \n",
       "4                1609  ...   inf  pres   \n",
       "\n",
       "                                          previous50 prev1  aller  aller_POS  \\\n",
       "0  à gouverner les Viles , sans que lon l' apelle...    d'  aller       VINF   \n",
       "1  ay dit . Quand Mercure ut fini la defense de F...     ,     và         VP   \n",
       "2  de Canada & Hochelaga au temps de post Tacques...   est   allé        VPP   \n",
       "3  qu' vn autre & n' en perdent point yn tour de ...   les   vont         VP   \n",
       "4  à l' vn des bours dudit lac ne nous apparoisso...     &  aller       VINF   \n",
       "\n",
       "          INF    next1 next1_POS  \\\n",
       "0     planter      des       P+D   \n",
       "1   prononcer       un       DET   \n",
       "2  rechercher    leurs       DET   \n",
       "3        voir       de       ADP   \n",
       "4    chercher  passage      NOUN   \n",
       "\n",
       "                                              next50  \n",
       "0  chous . Le fol ira tant et viendra , en donner...  \n",
       "1  arrest interlocutoire en cette maniere : Pour ...  \n",
       "2  pelleteries , Canada que pour icelles ils ont ...  \n",
       "3  plus grand chose : comme pardeça quand on pres...  \n",
       "4  tre ou cinq rivieres toutes sortantes dudit ff...  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f00e32-e48c-4151-b944-6255a36ed158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00292dbc-806f-4e0e-9e12-fb6324fe28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (fr['fr_source_textDate'] >= 1502) & (fr['fr_source_textDate'] <= 1542), # 1\n",
    "    (fr['fr_source_textDate'] >= 1543) & (fr['fr_source_textDate'] <= 1583), # 2\n",
    "    (fr['fr_source_textDate'] >= 1584) & (fr['fr_source_textDate'] <= 1624), # 3\n",
    "    (fr['fr_source_textDate'] >= 1625) & (fr['fr_source_textDate'] <= 1665), # 4\n",
    "    (fr['fr_source_textDate'] >= 1666) & (fr['fr_source_textDate'] <= 1699) # 5\n",
    "]\n",
    "\n",
    "values = ['1', '2', '3', '4', '5']\n",
    "\n",
    "fr.insert(1, 'period_category', np.select(conditions, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a285d4e-a3fa-4ef5-87b6-38d30b8b2d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeframe</th>\n",
       "      <th>period_category</th>\n",
       "      <th>kind</th>\n",
       "      <th>data_identifier</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text_id_per_author</th>\n",
       "      <th>authorId_textId</th>\n",
       "      <th>fr_source_filename</th>\n",
       "      <th>fr_source_title</th>\n",
       "      <th>fr_source_author</th>\n",
       "      <th>...</th>\n",
       "      <th>vpers</th>\n",
       "      <th>pos</th>\n",
       "      <th>previous50</th>\n",
       "      <th>prev1</th>\n",
       "      <th>aller</th>\n",
       "      <th>aller_POS</th>\n",
       "      <th>INF</th>\n",
       "      <th>next1</th>\n",
       "      <th>next1_POS</th>\n",
       "      <th>next50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>early</td>\n",
       "      <td>2</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS01</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35_1</td>\n",
       "      <td>WFtemp_LABE_Debat_de_folie_et_amour</td>\n",
       "      <td>Débat de folie et d'amour</td>\n",
       "      <td>Labé, Louise</td>\n",
       "      <td>...</td>\n",
       "      <td>3sg</td>\n",
       "      <td>inf</td>\n",
       "      <td>à gouverner les Viles , sans que lon l' apelle...</td>\n",
       "      <td>d'</td>\n",
       "      <td>aller</td>\n",
       "      <td>VINF</td>\n",
       "      <td>planter</td>\n",
       "      <td>des</td>\n",
       "      <td>P+D</td>\n",
       "      <td>chous . Le fol ira tant et viendra , en donner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>early</td>\n",
       "      <td>2</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS01</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>35_1</td>\n",
       "      <td>WFtemp_LABE_Debat_de_folie_et_amour</td>\n",
       "      <td>Débat de folie et d'amour</td>\n",
       "      <td>Labé, Louise</td>\n",
       "      <td>...</td>\n",
       "      <td>3sg</td>\n",
       "      <td>pres</td>\n",
       "      <td>ay dit . Quand Mercure ut fini la defense de F...</td>\n",
       "      <td>,</td>\n",
       "      <td>và</td>\n",
       "      <td>VP</td>\n",
       "      <td>prononcer</td>\n",
       "      <td>un</td>\n",
       "      <td>DET</td>\n",
       "      <td>arrest interlocutoire en cette maniere : Pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>early</td>\n",
       "      <td>3</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS13</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>47_1</td>\n",
       "      <td>LESCARBOT_cleaned</td>\n",
       "      <td>Histoire de la Nouvelle France (Lescarbot, Marc)</td>\n",
       "      <td>Lescarbot, Marc</td>\n",
       "      <td>...</td>\n",
       "      <td>3sg</td>\n",
       "      <td>past</td>\n",
       "      <td>de Canada &amp; Hochelaga au temps de post Tacques...</td>\n",
       "      <td>est</td>\n",
       "      <td>allé</td>\n",
       "      <td>VPP</td>\n",
       "      <td>rechercher</td>\n",
       "      <td>leurs</td>\n",
       "      <td>DET</td>\n",
       "      <td>pelleteries , Canada que pour icelles ils ont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>early</td>\n",
       "      <td>3</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS13</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>47_1</td>\n",
       "      <td>LESCARBOT_cleaned</td>\n",
       "      <td>Histoire de la Nouvelle France (Lescarbot, Marc)</td>\n",
       "      <td>Lescarbot, Marc</td>\n",
       "      <td>...</td>\n",
       "      <td>3pl</td>\n",
       "      <td>pres</td>\n",
       "      <td>qu' vn autre &amp; n' en perdent point yn tour de ...</td>\n",
       "      <td>les</td>\n",
       "      <td>vont</td>\n",
       "      <td>VP</td>\n",
       "      <td>voir</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>plus grand chose : comme pardeça quand on pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>early</td>\n",
       "      <td>3</td>\n",
       "      <td>french_original</td>\n",
       "      <td>EFS13</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>47_1</td>\n",
       "      <td>LESCARBOT_cleaned</td>\n",
       "      <td>Histoire de la Nouvelle France (Lescarbot, Marc)</td>\n",
       "      <td>Lescarbot, Marc</td>\n",
       "      <td>...</td>\n",
       "      <td>inf</td>\n",
       "      <td>pres</td>\n",
       "      <td>à l' vn des bours dudit lac ne nous apparoisso...</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>aller</td>\n",
       "      <td>VINF</td>\n",
       "      <td>chercher</td>\n",
       "      <td>passage</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>tre ou cinq rivieres toutes sortantes dudit ff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  timeframe period_category             kind data_identifier  author_id  \\\n",
       "0     early               2  french_original           EFS01         35   \n",
       "1     early               2  french_original           EFS01         35   \n",
       "2     early               3  french_original           EFS13         47   \n",
       "3     early               3  french_original           EFS13         47   \n",
       "4     early               3  french_original           EFS13         47   \n",
       "\n",
       "   text_id_per_author authorId_textId                   fr_source_filename  \\\n",
       "0                   1            35_1  WFtemp_LABE_Debat_de_folie_et_amour   \n",
       "1                   1            35_1  WFtemp_LABE_Debat_de_folie_et_amour   \n",
       "2                   1            47_1                    LESCARBOT_cleaned   \n",
       "3                   1            47_1                    LESCARBOT_cleaned   \n",
       "4                   1            47_1                    LESCARBOT_cleaned   \n",
       "\n",
       "                                    fr_source_title fr_source_author  ...  \\\n",
       "0                         Débat de folie et d'amour     Labé, Louise  ...   \n",
       "1                         Débat de folie et d'amour     Labé, Louise  ...   \n",
       "2  Histoire de la Nouvelle France (Lescarbot, Marc)  Lescarbot, Marc  ...   \n",
       "3  Histoire de la Nouvelle France (Lescarbot, Marc)  Lescarbot, Marc  ...   \n",
       "4  Histoire de la Nouvelle France (Lescarbot, Marc)  Lescarbot, Marc  ...   \n",
       "\n",
       "   vpers   pos                                         previous50 prev1  \\\n",
       "0    3sg   inf  à gouverner les Viles , sans que lon l' apelle...    d'   \n",
       "1    3sg  pres  ay dit . Quand Mercure ut fini la defense de F...     ,   \n",
       "2    3sg  past  de Canada & Hochelaga au temps de post Tacques...   est   \n",
       "3    3pl  pres  qu' vn autre & n' en perdent point yn tour de ...   les   \n",
       "4    inf  pres  à l' vn des bours dudit lac ne nous apparoisso...     &   \n",
       "\n",
       "   aller aller_POS         INF    next1 next1_POS  \\\n",
       "0  aller      VINF     planter      des       P+D   \n",
       "1     và        VP   prononcer       un       DET   \n",
       "2   allé       VPP  rechercher    leurs       DET   \n",
       "3   vont        VP        voir       de       ADP   \n",
       "4  aller      VINF    chercher  passage      NOUN   \n",
       "\n",
       "                                              next50  \n",
       "0  chous . Le fol ira tant et viendra , en donner...  \n",
       "1  arrest interlocutoire en cette maniere : Pour ...  \n",
       "2  pelleteries , Canada que pour icelles ils ont ...  \n",
       "3  plus grand chose : comme pardeça quand on pres...  \n",
       "4  tre ou cinq rivieres toutes sortantes dudit ff...  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4291c0-de51-49f5-815a-c29e5603f5cb",
   "metadata": {},
   "source": [
    "> Inserting the same period category in the metadata dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1025eb-af44-4ca1-8f3f-1e4e711ab8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_excel('/Users/paulineclaes/Documents/dta/thesis/finaldata/final_metadata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9022943-8629-4a5f-afb5-a66065b8106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english subset (which already has a classification per decade)\n",
    "meta_en_subset = meta[meta['transl_ref_srcTxt'] != 'srcTxt']\n",
    "# french subset (which does not yet have a classification per decade)\n",
    "meta_fr_subset = meta[meta['transl_ref_srcTxt'] == 'srcTxt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8605f47b-d53d-403f-9138-1ad90f88f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert period category in english data\n",
    "meta_en_subset.insert(3, \"period_category\", meta_en_subset.groupby([\"period\"], sort=True).ngroup()+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f077c181-278b-47bf-a7ac-603c4fbafcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert period category in French data\n",
    "meta_fr_subset.insert(3, 'period_category', np.select(conditions, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "450f1179-117f-498b-b4c8-8c43c11f28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating two data frames row-wise\n",
    "meta_new = pd.concat([meta_en_subset, meta_fr_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19df6802-6477-4c64-813c-43a8c7bb81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to excel file \n",
    "\n",
    "#meta_new.to_excel('/Users/paulineclaes/Documents/dta/thesis/finaldata/final_metadata.xlsx',\n",
    "#                 index=False,\n",
    "#                 na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30991daf-b94a-4616-862b-0e3f5c7ede1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
